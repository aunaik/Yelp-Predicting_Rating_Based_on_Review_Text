{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import normalize, RobustScaler, QuantileTransformer\n",
    "from sklearn import metrics \n",
    "from collections import Counter \n",
    "from imblearn.ensemble import BalanceCascade \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from imblearn.combine import SMOTEENN,SMOTETomek \n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling(X,Y):\n",
    "    Y=Y.as_matrix().flatten()\n",
    "    bc = BalanceCascade(random_state=0,\n",
    "                     estimator=LogisticRegression(random_state=0),\n",
    "                     n_max_subset=1)\n",
    "    X_resampled, Y_resampled = bc.fit_sample(X, Y)    \n",
    "    print('After Sampling: ',sorted(Counter(Y_resampled[0]).items()))\n",
    "    return (X_resampled, Y_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def over_sampling_SMOTEENN(X,y):\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_resampled, y_resampled = smote_enn.fit_sample(X, y)\n",
    "    print(sorted(Counter(y_resampled).items()))\n",
    "    return (X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def over_sampling_SMOTETomek(X,y):\n",
    "    smote_tomek = SMOTETomek(random_state=0)\n",
    "    X_resampled, y_resampled = smote_tomek.fit_sample(X, y)\n",
    "    print(sorted(Counter(y_resampled).items()))\n",
    "    return (X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(Y_test,predictions):\n",
    "    # evaluate predictions\n",
    "    accuracy = metrics.accuracy_score(Y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    print(\"RMSE:{0}\".format(metrics.mean_squared_error(Y_test, predictions)))\n",
    "    print(\"Classification Report\")\n",
    "    print(metrics.classification_report(Y_test, y_pred))\n",
    "    sumOfError = 0.0\n",
    "    errorDict = {}\n",
    "    samplingError = {}\n",
    "    totalError=0.0\n",
    "    for i in range(5):\n",
    "        samplingError[i] = {}\n",
    "        for j in range(5):\n",
    "            samplingError[i][j] = 0\n",
    "    sumOfSquareError = 0.0\n",
    "    for i in range(len(Y_test)):\n",
    "        error = (abs(Y_test[i] - predictions[i]))\n",
    "        if error not in errorDict.keys():\n",
    "            errorDict[error] = 0\n",
    "        errorDict[error] += 1\n",
    "        samplingError[int(Y_test[i])-1][int(predictions[i])-1] += 1\n",
    "        sumOfError += error/Y_test[i]\n",
    "        sumOfSquareError += error ** 2\n",
    "        totalError += error\n",
    "    \n",
    "    print('Total values : '+str(len(Y_test)))    \n",
    "    print(errorDict)\n",
    "    print(' \\t1\\t2\\t3\\t4\\t5')\n",
    "    print('1\\t'+str(samplingError[0][0])+'\\t'+str(samplingError[0][1])+'\\t'+str(samplingError[0][2])+'\\t'+str(samplingError[0][3])+'\\t'+str(samplingError[0][4]))\n",
    "    print('2\\t'+str(samplingError[1][0])+'\\t'+str(samplingError[1][1])+'\\t'+str(samplingError[1][2])+'\\t'+str(samplingError[1][3])+'\\t'+str(samplingError[1][4]))\n",
    "    print('3\\t'+str(samplingError[2][0])+'\\t'+str(samplingError[2][1])+'\\t'+str(samplingError[2][2])+'\\t'+str(samplingError[2][3])+'\\t'+str(samplingError[2][4]))\n",
    "    print('4\\t'+str(samplingError[3][0])+'\\t'+str(samplingError[3][1])+'\\t'+str(samplingError[3][2])+'\\t'+str(samplingError[3][3])+'\\t'+str(samplingError[3][4]))\n",
    "    print('5\\t'+str(samplingError[4][0])+'\\t'+str(samplingError[4][1])+'\\t'+str(samplingError[4][2])+'\\t'+str(samplingError[4][3])+'\\t'+str(samplingError[4][4]))\n",
    "    print(samplingError)\n",
    "    print(\"MAPE : \"+str((sumOfError/len(Y_test))*100))\n",
    "    print(\"RMSE :\"+str(sqrt(sumOfSquareError/len(Y_test))))\n",
    "    print(\"MAE:\"+str(totalError/len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_QuantileTransformer(X_train,Y_train,X_test):\n",
    "    qt = QuantileTransformer(n_quantiles=10, random_state=0)\n",
    "    qt.fit_transform(X_train,Y_train)\n",
    "    qt.transform(X_test)\n",
    "    return X_train,Y_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_RobustScaler(X_train,Y_train,X_test):\n",
    "    rs = RobustScaler()\n",
    "    rs.fit_transform(X_train,Y_train)\n",
    "    rs.transform(X_test)\n",
    "    return X_train,Y_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Normalization(X_train,X_test):\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_SVM(X_train, Y_train,X_test):\n",
    "    model = LinearSVC(C=0.1)\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_PCA(train, test):\n",
    "    pca = PCA(n_components=30)\n",
    "    pca.fit(train)\n",
    "    train = pca.transform(train)\n",
    "    test = pca.transform(test)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviewTable150.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df.loc[:,df.columns != 'Rating'],df['Rating'], test_size=0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=df.groupby('Rating')\n",
    "print(d['good'].agg(np.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run SVM using PCA and normalization\n",
    "x_train, x_test = Normalization(X_train,X_test)\n",
    "x_train, x_test = run_PCA(x_train, x_test)\n",
    "y_train=Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run SVM using PCA and QuantileTransformer\n",
    "x_train,y_train, x_test = run_QuantileTransformer(X_train,Y_train,X_test)\n",
    "x_train, x_test = run_PCA(x_train, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run svm using PCA and robustScaler\n",
    "x_train,y_train, x_test = run_RobustScaler(X_train,Y_train,X_test)\n",
    "x_train, x_test = run_PCA(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  if run SVM with under sampling\n",
    "x_train, y_train=sampling(x_train,y_train)\n",
    "x_train = x_train[0]\n",
    "y_train = y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  if run SVM with over sampling using SMOTEENN\n",
    "x_train, y_train = over_sampling_SMOTEENN(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  if run SVM with over sampling using SMOTETomek\n",
    "x_train, y_train = over_sampling_SMOTETomek(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  run Linear SVM and evaluate the result\n",
    "y_pred=run_SVM(x_train,y_train, x_test)\n",
    "evaluation(Y_test.values,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
